<HTML>
<HEAD>
<TITLE>VXL: vnl</TITLE>

<META NAME="description" CONTENT="VXL: vnl">
<META NAME="keywords" CONTENT="VXL: vnl">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<META NAME="Generator" CONTENT="texi2html @T2H_VERSION@">

</HEAD>

<BODY LANG="" BGCOLOR="#FFFFFF" TEXT="#000000" LINK="#0000FF" VLINK="#800080" ALINK="#FF0000">

<A NAME="SEC27"></A>
<TABLE CELLPADDING=1 CELLSPACING=1 BORDER=0>
<TR><TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book_3.html#SEC18"> &lt;&lt; </A>]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book_5.html#SEC38"> &gt;&gt; </A>]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book.html#SEC_Top">Top</A>]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book_toc.html#SEC_Contents">Contents</A>]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book_11.html#SEC56">Index</A>]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book_abt.html#SEC_About"> ? </A>]</TD>
</TR></TABLE>

<HR SIZE=2>
<H1> 4. vnl: Numerics </H1>
<!--docid::SEC27::-->
<P>

<BLOCKQUOTE>
<STRONG>Chapter summary</STRONG>:<BR>
C++ <EM>can</EM> be like Matlab, but faster and more powerful.
</BLOCKQUOTE>
<P>

The numerics library, <CODE>vnl</CODE> is intended to provide an environment for
numerical programming which combines the ease of use of packages like
Mathematica and MatLab with the speed of C and the elegance of C++.
It provides a C++ interface to the high-quality Fortran routines
made available in the public domain by numerical analysis researchers.
</P><P>

This release includes classes for
<UL>
<LI>Matrices and vectors.
The library is based on the old TargetJr/IUE
classes, which provide the standard operations without excessive overhead.
<P>

<LI>
Specialized classes for matrices and vectors with particular properties.
Class <CODE>vnl_diagonal_matrix</CODE> provides a fast and convenient diagonal
matrix, while fixed size matrices and vectors allow "fast-as-C"
computations (see <CODE>vnl_matrix_fixed&#60;T,n,m&#62;</CODE> and example subclasses
<CODE>vnl_double_3x3</CODE> and <CODE>vnl_double_3</CODE>).
<P>

<LI>Matrix decompositions.
Classes <CODE>vnl_svd&#60;T&#62;</CODE>, <CODE>vnl_symmetric_eigensystem&#60;T&#62; </CODE>,
<CODE>vnl_generalized_eigensystem</CODE>.
<P>

<LI>Real polynomials.
Class <CODE>vnl_real_polynomial</CODE> stores the coefficients
of a real polynomial, and provides methods of evaluation of the polynomial
at any <EM>x</EM>, while class <CODE>vnl_rpoly_roots</CODE> provides a root finder.
<P>

<LI>Optimization.
Classes <CODE>vnl_levenberg_marquardt</CODE>, <CODE>vnl_amoeba</CODE>,
<CODE>vnl_lbfgs</CODE>, <CODE>vnl_conjugate_gradient</CODE> allow optimization of
user-supplied functions either with <EM>or without</EM> user-supplied
derivatives.
<P>

<LI>Standardized homes for commonly used functions and constants.
Class <CODE>vnl_math</CODE> defines constants (<CODE>pi</CODE>, <CODE>e</CODE>, <CODE>eps</CODE>...) and
simple functions (<CODE>sqr</CODE>, <CODE>abs</CODE>, <CODE>rnd</CODE>...).
To quote the header "That's right, <CODE>M_PI</CODE> is nonstandard!"
Class <CODE>numeric_limits</CODE> is from the ISO standard document,
and provides a way to access basic limits of a type.  E.g.
<CODE>numeric_limits&#60;short&#62;::max()</CODE> returns the maximum value of a short.
</UL>
<P>

Most routines are implemented as wrappers around the high-quality Fortran
routines which have been developed by the numerical analysis community over
the last forty years and placed in the public domain.  The central
repository for these programs is the "netlib" server
<A HREF="http://www.netlib.org/">http://www.netlib.org/</A>.  The National Institute
of Standards and Technology (NIST) provides an excellent search interface
to this repository in its Guide to Available Mathematical Software (GAMS)
at <A HREF="http://gams.nist.gov">http://gams.nist.gov</A>, both as a decision tree and a text search.
</P><P>

<A NAME="SEC28"></A>
<H4> Compliance with the ANSI standard C++ library </H4>
<!--docid::SEC28::-->
The current draft of the ANSI standard (as at May 1996) includes classes
for 1-dimensional vectors (<CODE>valarray&#60;T&#62;</CODE>) and complex numbers (<CODE>
complex&#60;T&#62;</CODE>).  There is no standard for matrices.  The current vnl classes
are not implemented in terms of <CODE>valarray</CODE>, as there is a potential
perfomance hit, but in the future they might be.
<P>

<HR SIZE="6">
<A NAME="SEC29"></A>
<H2> 4.1 Example: Basic matrix and vector operations </H2>
<!--docid::SEC29::-->
<P>

This section provides a brief tutorial in using the main components of vnl.
The main components which vnl supplies are the vector and matrix classes.
The basic linear algebra operations on matrices and vectors are fully
supported.  Some very brief examples follow, but for the most part the
usage of the <CODE>vnl_vector</CODE> and <CODE>vnl_matrix</CODE> classes is (we hope)
obvious and intuitive.
</P><P>

Using these is easy, and is often modelled on matlab.  For example, this
declares a 3x4 matrix of <CODE>double</CODE>:
<TABLE><tr><td>&nbsp;</td><td class=example><pre>#include &#60;vnl/vnl_matrix.h&#62;
main() {
  vnl_matrix&#60;double&#62; P(3,4);
}
</pre></td></tr></table>Operators are overloaded as expected, so if we have another 3x4
matrix <VAR>Q</VAR>, we can add the two like this
<TABLE><tr><td>&nbsp;</td><td class=example><pre>vnl_matrix&#60;double&#62; R = P + Q;
</pre></td></tr></table>The <CODE>vnl_vector</CODE> is equally straightforward.  Here we make a 4-element
vector of doubles, premultiply it by <VAR>P</VAR>, and print the result:
<TABLE><tr><td>&nbsp;</td><td class=example><pre>vnl_vector&#60;double&#62; X(4);
cerr &#60;&#60; P*X;
</pre></td></tr></table>Several more examples are shown in Figure  <A HREF="book_4.html#fig:matrixbasics">fig:matrixbasics</A>.
</P><P>

<A NAME="IDX14"></A>
The vnl matrices are indexed from zero, as in C.  This is always a
difficult decision for C++ matrix libraries, as mathematical matrices use
indices starting from 1--the top left element of <VAR>A</VAR> is generally written 
<VAR>a_11</VAR>.  However, efficiently achieving this in C or C++ is a little
bit tricky, and can confuse some tools like Purify.  In the end, it was
decided that zero-based indexing was closer to being "not weird".
</P><P>

<TABLE><tr><td>&nbsp;</td><td class=smallexample><FONT SIZE=-1><pre>  vnl_matrix&#60;double&#62; A(3,3); // 3x3 matrix, elements not initialized
  vnl_matrix&#60;double&#62; B(3,3, 1.0); // 3x3 matrix, filled with ones.
  vnl_matrix&#60;double&#62; R(3,4); // Rectangular matrix
  cerr &#60;&#60; "A is " <&#60; A.<STRONG>rows</STRONG>() &#60;&#60; "x" &#60;&#60; A.<STRONG>columns</STRONG>() &#60;&#60; endl;
  cerr &#60;&#60; "A has a total of " <&#60; A.<STRONG>size</STRONG>() &#60;&#60; " elements" &#60;&#60; endl;
  A(0,0) = 2.0; // Set top-left component of A.
  A(3,3) = 0.0; // *** Error, (3,3) is outside the range of A.
  A.<STRONG>resize</STRONG>(3,4); // Change size of A, invalidating elements.
  R.<STRONG>update</STRONG>(A, 0, 1); // Copy A into R, starting at (0,1): last 3 cols
  R.<STRONG>set_column</STRONG>(0, B.<STRONG>get_column</STRONG>(0)); // Copy 1st col of B into R
  cerr &#60;&#60; R.<STRONG>extract</STRONG>(3,3, 0,1); // Print last 3 cols
  cerr &#60;&#60; R.<STRONG>get_n_columns</STRONG>(1, 3) const; // Ditto

  A.<STRONG>fill</STRONG>(0.0); // Set all elements of A to 0.0
  A.<STRONG>fill_diagonal</STRONG>(1.0); // Set diagonal elements to 1.0
  A.<STRONG>set_identity</STRONG>(); // Set A to identity matrix
  R = R.<STRONG>transpose</STRONG>(); // Make transposed copy, assign to R
  R.<STRONG>inplace_transpose</STRONG>(); // Transpose R without copying.
  A.<STRONG>flipud</STRONG>(); // Reverse order of rows of A
  A.<STRONG>fliplr</STRONG>(); // Reverse columns
  A.<STRONG>normalize_rows</STRONG>();  // Divide each row by its 2-norm
  A.<STRONG>scale_row</STRONG>(0, 2.0); // Multiply row 0 by 2
  memset(A.<STRONG>data_block</STRONG>(), 0); // Access A's raw storage
  fill(A.<STRONG>begin</STRONG>(), A.<STRONG>end</STRONG>(), 0.0); // Fill using STL iterators

  vnl_matrix&#60;double&#62; C = B + 0.1 * A; // Arithmetic
  C <STRONG>+=</STRONG> 2.3;
  vnl_matrix&#60;double&#62; Csqrt = C.<STRONG>apply</STRONG>(sqrt); // Square root all elements
  <STRONG>element_product</STRONG>(Csqrt, Csqrt); // Should be equal to C, modulo roundoff

  cerr &#60;&#60; A.<STRONG>fro_norm</STRONG>(); // Print sum of squares of elements
  cerr &#60;&#60; A.<STRONG>min_value</STRONG>(); // Print minimum element

  if (A.<STRONG>is_zero</STRONG>(1e-8)) cerr &#60;&#60; "Each element of A is within 1e-8 of zero\n";
  if (A.<STRONG>is_identity</STRONG>(1e-8)) cerr &#60;&#60; "(A - I) is_zero to 1e-8\n";

  A.<STRONG>read_ascii</STRONG>(cin); // Read A from standard input

</FONT></pre></td></tr></table><BLOCKQUOTE>
<STRONG>Figure 4.1:</STRONG>
Matrix basics.  A sample of the defined matrix operations.
<A NAME="fig:matrixbasics"></A>
</BLOCKQUOTE>
<P>

<HR SIZE="6">
<A NAME="SEC30"></A>
<H3> 4.1.1 Efficiency: Fixed-size matrices and vectors. </H3>
<!--docid::SEC30::-->
A C programmer looking at the above examples will immediately grumble about
the inefficient memory allocation that is being performed.  Let's look into
the construction of <VAR>P</VAR> in more detail.  One can guess that the line
<TABLE><tr><td>&nbsp;</td><td class=example><pre>vnl_matrix&#60;double&#62; P(3,4);
</pre></td></tr></table>might result in a sequence of actions something like the following:
<TABLE><tr><td>&nbsp;</td><td class=example><pre>struct vnl_matrix&#60;double&#62; P;
P.rows = 3;
P.columns = 4;
P.data = new double[P.rows * P.columns];
</pre></td></tr></table>The expensive part of this operation is the call to <VAR>new</VAR>, which might
involve many instructions, and even a bit of operating system activity.
(Typically a call to <VAR>new</VAR> or <VAR>malloc</VAR> will cost about as much as a
2x2 matrix multiply).
<P>

If the matrices are small, as in these examples, this cost is
significant--if they're bigger than about 20x20 it is not so important.
Always remember, when thinking about efficiency, to consider what else is
going on in the program.  For example, if a matrix is being read from disk,
the time taken to read the matrix will be many times greater than a few
copies.  If you are about to do a matrix multiply (an O(n^3) operation
after all), an O(n^2) copy or an O(1) <VAR>new</VAR> are not going to be hugely
significant.
</P><P>

However, for small matrices we should try to avoid calls to <VAR>new</VAR>, and
vnl provides some fixed-size matrices and vectors which do so.  Thus a more
efficient version of the above sequence would be
<TABLE><tr><td>&nbsp;</td><td class=example><pre>#include &#60;vnl/vnl_matrix_fixed.h&#62;
#include &#60;vnl/vnl_vector_fixed.h&#62;
main() {
  vnl_matrix_fixed&#60;double,3,4&#62; P;
  vnl_vector_fixed&#60;double,4&#62; X;
  cerr &#60;&#60; P*X;
}
</pre></td></tr></table>It's a bit clumsy typing these long names, so it is common to use
<CODE>typedef</CODE> to make shorter ones.  Indeed, a few are supplied with vnl,
for example <CODE>vnl_double_3x4</CODE>, so a more compact rendition of our
example is
<TABLE><tr><td>&nbsp;</td><td class=example><pre>#include &#60;vnl/vnl_double_3x4.h&#62;
#include &#60;vnl/vnl_double_4.h&#62;
main() {
  vnl_double_3x4 P;
  vnl_double_4 X;
  cerr &#60;&#60; P*X;
}
</pre></td></tr></table>Note again that in this example there will be no noticeable speedup,
because 99% of the runtime will be spent on the last line, printing the
vector.
</P><P>

Because some operations such as multiplication have been specially coded
for the fixed-size classes, they are also made more efficient by knowing
the sizes in advance.  For example, this snippet
<TABLE><tr><td>&nbsp;</td><td class=example><pre>vnl_double_3x3 R;               // Declare a 3x3 matrix 
vnl_double_3 x(1.0,2.0,3.0);    // Declare a 3-vector using local storage
vnl_double_3 rx = R * x;        // Multiply R by x and place the result in rx
</pre></td></tr></table>is expanded by many compilers into an open-coded sequence of 9 multiplies
and 6 adds.  Note that as the fixed-size objects are subclasses of the
generic objects, all the same operations apply to them.  Only those which
have been specifically coded to do so enjoy the increase in speed.
</P><P>

<HR SIZE="6">
<A NAME="SEC31"></A>
<H2> 4.2 Example: Matrix decomposition </H2>
<!--docid::SEC31::-->
<P>

The following fragment demonstrates use of the <CODE>vnl_svd&#60;double&#62;</CODE> class
to find the approximation of a 3x3 matrix <CODE>F</CODE> by the nearest matrix of
rank 2
<TABLE><tr><td>&nbsp;</td><td class=example><pre>vnl_double_3x3 rank2_approximate(const vnl_double_3x3&#38; F)
{
  // Compute singular value decomposition of F
  vnl_svd&#60;double&#62; svd (F);
  // Set smallest singular value to 0
  svd.W(2,2) = 0;
  // Recompose vnl_svd&#60;double&#62; into UWV^T
  return vnl_double_3x3(svd.recompose());
}
</pre></td></tr></table></P><P>

A more extensive example of the use of linear algebra is provided in
Figure 2, which contains a program to fit a hyperplane to
points read from standard input.
</P><P>

<TABLE><tr><td>&nbsp;</td><td class=example><pre>#include &#60;vnl/vnl_matops.h&#62;
#include &#60;vnl/algo/vnl_svd.h&#62;
#include &#60;vnl/algo/vnl_symmetric_eigensystem.h&#62;

main() {
  // Read points from stdin
  vnl_matrix&#60;double&#62; pts;
  cin &#62;&#62; pts;

  // Build design matrix D
  int npts = pts.rows();
  int dim = pts.columns();
  vnl_matrix&#60;double&#62; D(npts, dim+1);
  for(int i = 0; i &#60; npts; ++i) {
    for(int j = 0; j &#60; dim; ++j)
      D(i,j) = pts(i,j);
    D(i,dim) = 1;
  }

  // 1. Compute using vnl_svd&#60;double&#62;
  {
    vnl_svd&#60;double&#62; svd(D);
    vnl_vector&#60;double&#62; a = svd.nullvector();
    cout &#60;&#60; "vnl_svd<double> residual = " &#60;&#60; (D * a).magnitude() &#60;&#60; endl;
  }

  // 2. Compute using eigensystem of D'*D
  {
    vnl_symmetric_eigensystem&#60;double&#62;  eig(D.transpose() * D);
    vnl_vector&#60;double&#62; a = eig.get_eigenvector(0);
    cout &#60;&#60; "Eig residual = " &#60;&#60; (D * a).magnitude() &#60;&#60; endl;
  }
}
</pre></td></tr></table><BLOCKQUOTE>
<STRONG>Figure 4.2:</STRONG>
Example of linear algebra operations. Points are read from stdin
into matrix <CODE>pts</CODE>, and a hyperplane fitted using two different methods.
<A NAME="fig:planefit"></A>
</BLOCKQUOTE>
<P>

<HR SIZE="6">
<A NAME="SEC32"></A>
<H2> 4.3 Optimization </H2>
<!--docid::SEC32::-->
The package currently provides only for nonlinear least squares, rather
than general function minimization.  This means that the function to be
minimized must be the norm of a multivariate function.  However, this often
the case in vision problems, and allows us to use the powerful
Levenberg-Marquardt algorithm.  As an example of function minimization we
shall consider the "notorious" Rosenbrock function:
<TABLE><tr><td>&nbsp;</td><td class=example><pre>f(x, y) = [ 10(y - x^2) ]
          [    1-x      ]
</pre></td></tr></table>The graph of <EM>f^2</EM> is plotted below.
<P>

<CENTER><IMG SRC="rosenbrock.png" ALT="rosenbrock"></CENTER>
<BLOCKQUOTE>
<A NAME="fig:banana"></A>
The Rosenbrock "banana" function, used as an optimization test
case.  Optimization starts on one side of the valley, and must find the
minimum around the corner.
</BLOCKQUOTE>
<P>

We first derive a function object from <CODE>vnl_least_squares_function</CODE>.
The function object must initialize the base class with the number of
variables, and the number of residuals or unknowns.  In this case, both
domain and range are two dimensional.  The constructor must also supply a
<CODE>no_gradient</CODE> flag if the function <CODE>gradf</CODE> has not been
implemented.
<TABLE><tr><td>&nbsp;</td><td class=example><pre>struct Rosenbrock : public vnl_least_squares_function {
  Rosenbrock(): vnl_least_squares_function(2, 2, no_gradient) {}
};
</pre></td></tr></table></P><P>

Then the abstract method <CODE>f</CODE> is implemented, which evaluates the
function.  Any data required for the evaluation can be stored in the class
and will be available whenever <CODE>f</CODE> is called.
<TABLE><tr><td>&nbsp;</td><td class=example><pre>  double f(const vnl_vector&#60;double&#62;&#38; x, vnl_vector&#60;double&#62;&#38; fx) {
    fx[0] = 10 * (x[1] - vnl_math_sqr(x[0]));
    fx[1] = 1 - x[0];
  }
</pre></td></tr></table>In order to perform the minimization, a <CODE>vnl_levenberg_marquardt</CODE> compute
object is constructed, passing the <CODE>vnl_least_squares_function</CODE>.
<TABLE><tr><td>&nbsp;</td><td class=example><pre>Rosenbrock f;
vnl_levenberg_marquardt lm(f);
</pre></td></tr></table>Having provided an initial estimate of the solution in vector <CODE>x</CODE>, the
minimization is performed:
<TABLE><tr><td>&nbsp;</td><td class=example><pre>lm.minimize(x);
</pre></td></tr></table>after which the vector <CODE>x</CODE> contains the minimizing parameters.
</P><P>

<HR SIZE="6">
<A NAME="SEC33"></A>
<H2> 4.4 Design issues </H2>
<!--docid::SEC33::-->
This section documents some design decisions with which people might
disagree.  Please let me know how you feel on these issues.  It's also a
malleable to-do list.  The most important consideration has been to
provide simple lightweight interfaces that nevertheless allow for maximum
efficiency and flexibility.
<P>

<HR SIZE="6">
<A NAME="SEC34"></A>
<H3> 4.4.1 Computation in constructors </H3>
<!--docid::SEC34::-->
<A NAME="sec:computors"></A>
As noted above, a common model in this package is that the compute objects
perform computation within the constructors.  While this is slightly
distasteful from a traditional C++ viewpoint, it offers a number of
advantages in both efficiency and ease of use.
<P>

The philosophical argument, say in the case of SVD, is that SVD is a noun.
The natural description is "The SVD of a matrix M" which is expressed in
C++ as <CODE>vnl_svd&#60;double&#62; svd(M) </CODE>.
</P><P>

Storage for the results of a computation is provided by the compute object
which is convenient, allowing client code to access only those results in
which it is interested.  Local storage is also more efficient, as objects
are constructed at the correct size, and initialized immediately.  In
contrast, passing empty objects to a function will generally involve a
resize operation, while returning a structure will incur a speed penalty
due to the necessary copy operations.
</P><P>

Namespace clutter is avoided in the <CODE>vnl_matrix</CODE> class.  While svd()
is a perfectly reasonable method for a matrix, there are many other
decompositions that might be of interest, and adding them all would make
for a very large matrix class, even though many methods might not be of
general interest.
</P><P>

The model extends readily to <EM>n</EM>-ary operations such as generalized
eigensystems, which combine two objects to produce others.  Such operations
cannot be methods on just one matrix.
</P><P>

<HR SIZE="6">
<A NAME="SEC35"></A>
<H3> 4.4.2 Fixed-size classes </H3>
<!--docid::SEC35::-->
The classes which provide for fast fixed-size matrices and vectors are
essential in a system which wants to make claims for efficiency.  In
addition, a great many uses of these objects <EM>do</EM> know the size in
advance.  In this case code using say <CODE>vnl_double_3</CODE> is more efficient (as
well as more self-documenting) than the equivalent referring to a
<CODE>vnl_vector</CODE> of unknown size.
<P>

<HR SIZE="6">
<A NAME="SEC36"></A>
<H3> 4.4.3 Transposing for Fortran </H3>
<!--docid::SEC36::-->
In calling Fortran code, the first difficulty that becomes apparent is that
Fortran arrays are stored column-wise, while traditional `C' arrays are
stored rowwise -- a trend that is followed by the <CODE>vnl_matrix</CODE> class.
One solution is simply to store C++ arrays columnwise, and this was an
early plan for the IUE.
<P>

I have not done anything to alleviate this for two reasons -- most routines
we call are expensive enough (i.e. <EM>O(n^3)</EM>) that the <EM>O(n^2)</EM> copy
operation is only a small performance hit.  Secondly, many decompositions
satisfy a transpose-equivalence relationship.  For example suppose we wish
to use a Fortran matrix multiply which has been hand-optimized for some
particular machine.  Such a routine may be declared
<TABLE><tr><td>&nbsp;</td><td class=example><pre>mmul(A, B, C) // Computes C = A B, fortran storage
</pre></td></tr></table>To use this with row-stored arrays, we recall the simple identity
<TABLE><tr><td>&nbsp;</td><td class=example><pre>C = (C')' = (B' A')' = AB
</pre></td></tr></table>and therefore call <CODE>mmul(B, A, C)</CODE>, reversing the order of parameters
<EM>A</EM> and <EM>B</EM>.  The fortran code will lay down the result of
<EM>B' A'</EM> into the columns of <EM>C</EM>, thereby computing <EM>C' =
B' A'</EM> from the point of view of the caller.
</P><P>

This however, doesn't apply to the vnl_svd&#60;double&#62;, as algorithms generally require only the
"economy-size" version where size(U) = size(M) in <EM>U S V' = M</EM>.  This
is <EM>O(mn^2)</EM> flops rather than <EM>O(m^2n)</EM> for the fullsize one.  Using the
transpose-equivalence would mean a doubling of the computation time, as the
"economy-size" decomposition is only implemented for <EM>m &#62; n</EM>.  If someone
does need the full size decomposition, a flag could be added or a new <CODE>vnl_svd</CODE>
class written.
</P><P>

<HR SIZE="6">
<A NAME="SEC37"></A>
<H2> 4.5 Future work </H2>
<!--docid::SEC37::-->
Many of the existing methods are unimplemented, or could benefit from
optimization.  Users can contribute code to address these deficiencies
based on the existing examples, and using the conversion hints in
Appendix~A.  In addition there are many algorithms that ought to be
included, listed roughly in order of priority:
<UL>

<LI>
Additional matrix decompositions in the same vein, including an updateable
QR, a basic LU, etc.
<P>

<LI>Choice of backend functions--for optimization one might prefer Powell,
or even simulated annealing.  For matrix decompositions, particular users
might prefer to interface to NAG or IMSL routines.  These choices must be
allowed to be made easily, thereby encouraging the comparison of algorithms
and of alternative implementations.
<P>

<LI>Many classes are defined as double-only rather than templated.
I will use default template arguments when the compilers support them.
</UL>
<P>

<A NAME="vil"></A>
<HR SIZE="6">
<TABLE CELLPADDING=1 CELLSPACING=1 BORDER=0>
<TR><TD VALIGN="MIDDLE" ALIGN="LEFT">[ &lt;&lt; ]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT">[ &gt;&gt; ]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT"> &nbsp; <TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book.html#SEC_Top">Top</A>]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book_toc.html#SEC_Contents">Contents</A>]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book_11.html#SEC56">Index</A>]</TD>
<TD VALIGN="MIDDLE" ALIGN="LEFT">[<A HREF="book_abt.html#SEC_About"> ? </A>]</TD>
</TR></TABLE>
</BODY>
</HTML>
